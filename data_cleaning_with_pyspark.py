# -*- coding: utf-8 -*-
"""DATA CLEANING  WITH PYSPARK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rf5ZaFX_e1-1XZx19VBG2dcrULV7SG6a
"""

!apt-get install openjdk-11-jdk -y
!pip install pyspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"

from pyspark.sql import SparkSession

# Initialize Spark Session
spark = SparkSession.builder.appName("DataCleaning").getOrCreate()

from pyspark.sql import Row

# Create example data
data = [
    Row(id=1, name="Alice", age=25),
    Row(id=2, name=None, age=30),
    Row(id=3, name="Charlie", age=None),
    Row(id=4, name="Alice", age=25),  # duplicate
]

df = spark.createDataFrame(data)
df.show()

# Drop rows with any missing values
df_cleaned = df.dropna()
df_cleaned.show()

# Alternatively, fill missing values
# df_filled = df.fillna({'name': 'Unknown', 'age': 0})
# df_filled.show()

df_final = df_cleaned.dropDuplicates()
df_final.show()

df_final.toPandas().to_csv("cleaned_data.csv", index=False)
from google.colab import files
files.download("cleaned_data.csv")

